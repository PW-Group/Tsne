{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"Knowledge Distllation Method\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data.dataloader as Data\n",
    "import torchvision #torchvision模块包括了一些图像数据集,如MNIST,cifar10等\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系統找不到指定的路徑。: 'Desktop/data/data_2_N\\\\train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5d906b7b7ae5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Desktop/data/data_2_N'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n\u001b[0m\u001b[0;32m     20\u001b[0m               for x in ['train', 'val']}\n\u001b[0;32m     21\u001b[0m dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=128,                                             \n",
      "\u001b[1;32m<ipython-input-2-5d906b7b7ae5>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Desktop/data/data_2_N'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n\u001b[0m\u001b[0;32m     20\u001b[0m               for x in ['train', 'val']}\n\u001b[0;32m     21\u001b[0m dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=128,                                             \n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[0;32m    203\u001b[0m     def __init__(self, root, transform=None, target_transform=None,\n\u001b[0;32m    204\u001b[0m                  loader=default_loader, is_valid_file=None):\n\u001b[1;32m--> 205\u001b[1;33m         super(ImageFolder, self).__init__(root, loader, IMG_EXTENSIONS if is_valid_file is None else None,\n\u001b[0m\u001b[0;32m    206\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m                                           \u001b[0mtarget_transform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[0;32m     92\u001b[0m         super(DatasetFolder, self).__init__(root, transform=transform,\n\u001b[0;32m     93\u001b[0m                                             target_transform=target_transform)\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_find_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m         \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m_find_classes\u001b[1;34m(self, dir)\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[0mNo\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0msubdirectory\u001b[0m \u001b[0mof\u001b[0m \u001b[0manother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \"\"\"\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[0mclass_to_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mcls_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 系統找不到指定的路徑。: 'Desktop/data/data_2_N\\\\train'"
     ]
    }
   ],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Loade dataset\n",
    "data_dir = 'Desktop/data/data_2_N'\n",
    "  \n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
    "              for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=128,                                             \n",
    "                        shuffle=True, num_workers=0)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "# Determine the use of GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\ntrain_loader:\\n',dataloaders['train'].dataset)\n",
    "print('\\ntrain_data:\\n',image_datasets['train'])\n",
    "print('\\nlen:\\n',len(image_datasets['train']))\n",
    "print('\\nlen:\\n',len(image_datasets['val']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_labels(lowDWeights, labels):\n",
    "    plt.cla() #clear当前活动的坐标轴\n",
    "    X, Y = lowDWeights[:, 0], lowDWeights[:, 1] #把Tensor的第1列和第2列,也就是TSNE之后的前两个特征提取出来,作为X,Y\n",
    "    for x, y, s in zip(X, Y, labels):\n",
    "        c = cm.rainbow(int(255 * s / 9));\n",
    "        #plt.text(x, y, s, backgroundcolor=c, fontsize=9)\n",
    "        plt.text(x, y, str(s),color=c,fontdict={'weight': 'bold', 'size': 9}) #在指定位置放置文本\n",
    "    plt.xlim(X.min(), X.max());\n",
    "    plt.ylim(Y.min(), Y.max());\n",
    "    plt.title('Visualize last layer');\n",
    "    plt.show();\n",
    "    plt.pause(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = torch.load('Desktop/model_1016_2020/model/Model_painting/FT_AlexNet-FLR_Paintings.pkl')\n",
    "cnn =cnn.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"定义损失函数-这里默认是交叉熵函数\"\"\"\n",
    "\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\"\"\"初始化:优化器\"\"\"\n",
    "\n",
    "optimizer = optim.SGD(cnn.classifier[6].parameters(), lr=1e-2, momentum=0.9)\n",
    "#optimizer = optim.Adam(cnn.parameters(), lr=0.01)  #list(cnn.parameters())会给出一个参数列表,记录了所有训练参数(W和b)的数据\n",
    "#optimizer =optim.Adam([ {'params': cnn.conv1.weight}, {'params': cnn.conv1.bias, 'lr': 0.002,'weight_decay': 0 },\n",
    "#                         {'params': cnn.conv2.weight}, {'params': cnn.conv2.bias, 'lr': 0.002,'weight_decay': 0 },\n",
    "#                         {'params': cnn.fc1.weight}, {'params': cnn.fc1.bias, 'lr': 0.002,'weight_decay': 0 },\n",
    "#                         {'params': cnn.fc2.weight}, {'params': cnn.fc2.bias, 'lr': 0.002,'weight_decay': 0 },\n",
    "#                         {'params': cnn.conv3.weight}, {'params': cnn.conv3.bias, 'lr': 0.002,'weight_decay': 0 },\n",
    "#                         {'params': cnn.conv4.weight}, {'params': cnn.conv4.bias, 'lr': 0.002,'weight_decay': 0 },\n",
    "#                         {'params': cnn.conv5.weight}, {'params': cnn.conv5.bias, 'lr': 0.002,'weight_decay': 0 },], lr=0.001, weight_decay=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"训练\"\"\"\n",
    "\n",
    "def train(epoch):\n",
    "    print('epoch {}'.format(epoch))\n",
    "    #直接初始化为0的是标量,tensor调用item()将返回标量值\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    #step是enumerate（）函数自带的索引，从0开始\n",
    "    for step, (batch_x, batch_y) in enumerate(dataloaders['train']):\n",
    "        # 把batch_x和batth_y移动到GPU\n",
    "        batch_x = batch_x.cuda()\n",
    "        batch_y = batch_y.cuda()\n",
    "        # 正向传播\n",
    "        #out,_ = cnn(batch_x)\n",
    "        out = cnn(batch_x)\n",
    "        loss = loss_func(out, batch_y)\n",
    "        train_loss += loss.item()\n",
    "        # torch.max(tensor,dim:int):tensor找到第dim维度(第0维度是数据下标)上的最大值\n",
    "        # return: 第一个Tensor是该维度的最大值,第二个Tensor是最大值相应的下标\n",
    "        pred = torch.max(out, 1)[1]\n",
    "        # 直接对逻辑量进行sum,将返回True的个数\n",
    "        train_correct = (pred == batch_y).sum()\n",
    "        train_acc += train_correct.item()\n",
    "        if step % 20 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, step * len(batch_x), len(dataloaders['train'].dataset),100. * step / len(dataloaders['train']), loss.item()))\n",
    "\n",
    "        #反向传播\n",
    "        optimizer.zero_grad() # 所有参数的梯度清零\n",
    "        loss.backward() #即反向传播求梯度\n",
    "        optimizer.step() #调用optimizer进行梯度下降更新参数\n",
    "    print('Train Loss: {:.6f}, Acc: {:.6f}'.format(train_loss / (len(image_datasets['train'])), train_acc / (len(image_datasets['train']))))\n",
    "\n",
    "from matplotlib import cm\n",
    "try:\n",
    "    from sklearn.manifold import TSNE; HAS_SK = True\n",
    "except:\n",
    "    HAS_SK = False; print('Please install sklearn for layer visualization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"准确率\"\"\"\n",
    "\n",
    "def test():\n",
    "    cnn.eval()\n",
    "    eval_loss = 0\n",
    "    eval_acc = 0\n",
    "    # 打开imshow()交互模式:更新图像后直接执行以后的代码,不阻塞在plt.show()\n",
    "    plt.ion()\n",
    "    #无需反向传播计算梯度,不需要进行求导运算\n",
    "    with torch.no_grad():\n",
    "        for step, (batch_x, batch_y) in enumerate(dataloaders['val']):\n",
    "            batch_x = batch_x.cuda()\n",
    "            batch_y = batch_y.cuda()\n",
    "            #out,last_layer = cnn(batch_x)\n",
    "            out = cnn(batch_x)\n",
    "            loss = loss_func(out, batch_y)\n",
    "            #loss =  += F.nll_loss(out, batch_y, size_average=False).item()\n",
    "            eval_loss += loss.item()\n",
    "            pred = torch.max(out, 1)[1]\n",
    "            num_correct = (pred == batch_y).sum()\n",
    "            eval_acc += num_correct.item()\n",
    "            #若需绘图,将下面代码块注释去掉\n",
    "            if step % 100 == 0:\n",
    "                #t-SNE 是一种非线性降维算法，非常适用于高维数据降维到2维或者3维，进行可视化\n",
    "                tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)\n",
    "                #最多只画500个点\n",
    "                plot_only = 500\n",
    "                #fit_transform函数把last_layer的Tensor降低至2个特征量,即3个维度(2个维度的坐标系)\n",
    "                low_dim_embs = tsne.fit_transform(out.cpu().data.numpy()[:plot_only, :])\n",
    "                labels = batch_y.cpu().numpy()[:plot_only]\n",
    "                plot_with_labels(low_dim_embs, labels)\n",
    "                \n",
    "            #若需绘图,将上面代码块注释去掉 \n",
    "    print('Test Loss: {:.6f}, Accuracy: {}/{} ({:.2f}%'.format(eval_loss / (len(image_datasets['val'])),eval_acc, len(image_datasets['val']) ,100.*eval_acc / (len(image_datasets['val']))))\n",
    "    plt.figure()\n",
    "    plt.show()\n",
    "    plt.savefig('Desktop/tsne_pic/FT_AlexNet-FLR_Paintings')\n",
    "    plt.ioff()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 21):\n",
    "    train(epoch)\n",
    "    test() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
